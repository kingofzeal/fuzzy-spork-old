<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>The Fuzzy Spork</title>
  
  <subtitle>Strange but entertaining food for thought</subtitle>
  <link href="/fuzzy-spork/atom.xml" rel="self"/>
  
  <link href="http://kingofzeal.github.io/fuzzy-spork/"/>
  <updated>2018-02-01T14:28:15.682Z</updated>
  <id>http://kingofzeal.github.io/fuzzy-spork/</id>
  
  <author>
    <name>James McCollum</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Searching for SSL Certificates based on SAN entries</title>
    <link href="http://kingofzeal.github.io/fuzzy-spork/2017/12/21/Searching-for-SSL-Certificates-based-on-SAN-entries/"/>
    <id>http://kingofzeal.github.io/fuzzy-spork/2017/12/21/Searching-for-SSL-Certificates-based-on-SAN-entries/</id>
    <published>2017-12-21T14:00:00.000Z</published>
    <updated>2018-02-01T14:28:15.682Z</updated>
    
    <content type="html"><![CDATA[<p>Lately, I’ve been playing with <a href="https://letsencrypt.org/" target="_blank" rel="noopener">Lets Encrypt</a> as a means to encrypt public(ish) web-based services I run on my local server. It’s actually remarkable what this non-profit group has accomplished when it comes to SSL - they offer free, automated SSL certificates to anybody who wants them. They even support SAN certificates (those that cover multiple, explicitly-named DNS entries), and starting in January they will offer wildcard certificates. I will tell anybody who is willing to listen, and who is looking to avoid paying paying $50+ for an SSL certificate, about them and encourage everyone to look into their service. <a id="more"></a></p><p>The only real downside (which some argue isn’t really a downside) is that these certificates generally have a pretty short lifetime - they last 90 days, with no options for longer lengths (unlike other CAs). There are reasons for this, but they make up for this by being completely automated - it literally takes seconds to get a new certificate. If you are on a Windows machine, you can snag a tool from Github which not only handles the request for the certificate, but also installs it, updates your IIS bindings, and creates a scheduled task that will look at the state of your certificates and, if needed (generally after about 60 days - 30 days before they expire), automatically renew them. It is as close to a set it and forget it system, and you don’t have to run the risk of letting your certificates expire while you wait for a new one.</p><p>However, having constantly (and automatically) changing SSL certificates can preset an interesting challenge if you use Octopus Deploy to deploy your websites. If you are only deploying a single website, then the answer is trivial - there is a <a href="http://library.octopusdeploy.com/step-templates/bc81b8a6-dc56-4769-87b5-650af7a38162/actiontemplate-lets-encrypt-create-ssl-certificate" target="_blank" rel="noopener">community step template</a> that takes care of most of the hard work for you. </p><p>But this only renews the certificate when you do to deploy a project - if you could potentially go more than 90 days between deployments, you run the risk of the certificate expiring. There are features that help mitigate this, such as setting up Octopus notifications when a certificate is about to expire, but ultimately you still need to perform a deployment to get the new certificate.<br>Additionally, this really only works if you have a single website. If you are deploying multiple websites to the same IIS service, and you want to bind all of them to port 443 (the default SSL port), you need a SAN certificate, which the current template doesn’t really addresses. </p><p>There is a currently outstanding <a href="https://octopusdeploy.uservoice.com/forums/170787-general/suggestions/15045072-support-letsncrypt-for-octopus-certificates" target="_blank" rel="noopener">UserVoice suggestion</a> to address this by adding Lets Encrypt a first-class citizen, but it looks like that’s part of <a href="https://github.com/OctopusDeploy/Issues/issues/2701" target="_blank" rel="noopener">‘Phase 3’</a> of managing certificates. In the meantime, there is a post on the UserVoice suggestion that offers a workaround: run a script that finds a given certificate by Subject name (often the primary DNS Name the certificate was issued for), and update the thumbprint in the deployment process with whatever certificate is currently there.</p><p>For now, this seems like a better option. It doesn’t require any unnecessary deployments - the Lets Encrypt certificate is presumably scheduled to be updated on the server periodically, and the current thumbprint is simply obtained and used at deployment time. This allows for greater flexibility in how certificates are managed, by being able to use SAN or (eventually) wildcard certificates. While they aren’t being managed by Octopus, which can be argued is the best place to have them, at the very least having a new certificate for the site won’t interfere with the deployment process. </p><p>However, there is one last hurdle - the certificate is identified by Subject, which may not necessarily represent the DNS entry for the website we’re deploying to. In the case of a SAN certificate, if it covers 4 websites, you will need to provide this detail (and hope it doesn’t change) for 3 out of the 4 websites. This is less than ideal, as a change in one project may mean a change in others.</p><p>After much trial and error, I found that altering the script a little bit allows us to search for a certificate that covers the website we’re deploying. I’ve turned this into a Step Template so we can re-use the logic in multiple projects, but this is the core of the script:</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">Write-Host</span> <span class="string">"Search Enabled: <span class="variable">$SearchDynamicCertificate</span>"</span></span><br><span class="line"><span class="built_in">Write-Host</span> <span class="string">"Default Thumbprint: <span class="variable">$DefaultThumbprint</span>"</span></span><br><span class="line"><span class="built_in">Write-Host</span> <span class="string">"DNS Subject: <span class="variable">$DnsSubject</span>"</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$disoveredThumbprint</span> = <span class="variable">$DefaultThumbprint</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$SearchDynamicCertificate</span>)&#123;</span><br><span class="line">    <span class="variable">$thumbprint</span> = <span class="built_in">Get-ChildItem</span> Cert:\LocalMachine\My -Recurse | <span class="built_in">Where-Object</span> &#123;</span><br><span class="line">        <span class="variable">$_</span>.NotAfter <span class="nomarkup">-gt</span> (<span class="built_in">get-date</span>) -and <span class="variable">$_</span>.NotBefore <span class="nomarkup">-le</span> (<span class="built_in">get-date</span>)</span><br><span class="line">    &#125; | <span class="built_in">Select-Object</span> -Property Thumbprint,@&#123;</span><br><span class="line">        Name=<span class="string">"San"</span>;</span><br><span class="line">        Expression=&#123;<span class="variable">$_</span>.Extensions | <span class="built_in">Where-Object</span> &#123;<span class="variable">$_</span>.Oid.FriendlyName <span class="nomarkup">-eq</span> <span class="string">"subject alternative name"</span>&#125;&#125;</span><br><span class="line">    &#125; | <span class="built_in">Where-Object</span> &#123;</span><br><span class="line">        <span class="variable">$_</span>.San.Count <span class="nomarkup">-gt</span> <span class="number">0</span> -and </span><br><span class="line">        <span class="variable">$_</span>.San.Format(<span class="number">1</span>).Contains(<span class="string">"DNS Name=<span class="variable">$DnsSubject</span>"</span>)</span><br><span class="line">    &#125; | <span class="built_in">Select-Object</span> -ExpandProperty Thumbprint</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (<span class="nomarkup">-not</span> [string]::IsNullOrWhiteSpace(<span class="variable">$thumbprint</span>))&#123;</span><br><span class="line">        <span class="built_in">Write-Host</span> <span class="string">"Found certificate <span class="variable">$thumbprint</span> that covers <span class="variable">$DnsSubject</span>"</span></span><br><span class="line">        <span class="variable">$disoveredThumbprint</span> = <span class="variable">$thumbprint</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">Write-Host</span> <span class="string">"Using <span class="variable">$disoveredThumbprint</span> for DiscoveredThumbprint"</span></span><br><span class="line">Set-OctopusVariable -name <span class="string">"DiscoveredThumbprint"</span> -value <span class="string">"<span class="variable">$disoveredThumbprint</span>"</span></span><br></pre></td></tr></table></figure><p><code>DefaultThumbprint</code>, <code>SearchDynamicCertificate</code> and <code>DnsSubject</code> are all parameters of the template, and in our case they map directly to the original <code>thumbprint</code> project variable, a new checkbox project variable, and the binding DNS project variable, respectively. </p><p>In a nutshell, it goes through all certificates in the certificate store, filters out any that are expired or predated, extracts the SAN entries, and returns the thumbprint of any certificates that have a SAN entry for the given address, which is then set as an output variable (<code>DiscoveredThumbprint</code>). This <em>could</em> return multiple certificates, if they cover the same DNS entries, but generally speaking you shouldn’t see that very much, if at all.</p><p>If no certificate is found, or if <code>SearchDynamicCertificate</code> is false, then it just uses the default thumbprint provided. This process does assume that IIS is setup correctly (only one certificate per port, regardless of how many websites bind to that port), and does not do any validation that the certificate found is the correct one to be used. There are probably additional checks that could be performed around that area, but for now this works for “happy-path” deployments.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Lately, I’ve been playing with &lt;a href=&quot;https://letsencrypt.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Lets Encrypt&lt;/a&gt; as a means to encrypt public(ish) web-based services I run on my local server. It’s actually remarkable what this non-profit group has accomplished when it comes to SSL - they offer free, automated SSL certificates to anybody who wants them. They even support SAN certificates (those that cover multiple, explicitly-named DNS entries), and starting in January they will offer wildcard certificates. I will tell anybody who is willing to listen, and who is looking to avoid paying paying $50+ for an SSL certificate, about them and encourage everyone to look into their service.
    
    </summary>
    
    
      <category term="Devops" scheme="http://kingofzeal.github.io/fuzzy-spork/tags/Devops/"/>
    
      <category term="LetsEncrypt" scheme="http://kingofzeal.github.io/fuzzy-spork/tags/LetsEncrypt/"/>
    
      <category term="SSL Certificates" scheme="http://kingofzeal.github.io/fuzzy-spork/tags/SSL-Certificates/"/>
    
      <category term="Octopus Deploy" scheme="http://kingofzeal.github.io/fuzzy-spork/tags/Octopus-Deploy/"/>
    
  </entry>
  
  <entry>
    <title>Using Octopus Deploy to deploy multiple projects at once</title>
    <link href="http://kingofzeal.github.io/fuzzy-spork/2017/12/14/Using-Octopus-Deploy-to-deploy-multiple-projects-at-once/"/>
    <id>http://kingofzeal.github.io/fuzzy-spork/2017/12/14/Using-Octopus-Deploy-to-deploy-multiple-projects-at-once/</id>
    <published>2017-12-14T14:00:00.000Z</published>
    <updated>2018-02-01T14:28:15.682Z</updated>
    
    <content type="html"><![CDATA[<p>We use Octopus Deploy at my workplace to handle all of our releases. The tool is one of the best I’ve had the pleasure of dealing with, and the more I interact with it, the more I realize just how powerful, yet flexible, it is. I will gladly recommend it to anyone who is looking for a way of releasing any kind of software. </p><p>However, there is always room for improvement. In this case, not necessarily improvement with the software package, but how we use it. <a id="more"></a></p><h2 id="Environment-Overview"><a href="#Environment-Overview" class="headerlink" title="Environment Overview"></a>Environment Overview</h2><p>Before we get to the specific problems, let me first go through what our deployment process generally looks like.</p><p>We operate on a two week release cycle. At the end of each cycle, we package all our products up and send it to Octopus. From there we create a release for each product, which is then pushed to a Staging environment for final testing. </p><p>We have 4 major products that are released using 7 Octopus projects, and each of the products may or may not have changes during each release cycle. We offer our products as an on-premise package and as a hosted cloud-based SAAS offering, and have an active Beta program for customers who want early access to new features. To accommodate this, we have a total of 6 environments - <code>Development</code>, <code>Staging</code>, <code>On Site Beta</code>, <code>Hosted Beta</code>, <code>On Site Release</code> and <code>Hosted Release</code>.</p><p>Finally, because of our SAAS offering, we make heavy use of tenants - each of our customers has their own discrete copy of the software, but on a system which may be shared by other customers.</p><p>Overall, we likely have what many would consider a ‘small’ setup for Octopus - I have heard of companies that have 10s of environments and hundreds of projects. While we may be small, we are at the point where to take care of everything manually would take several hours of work on a frequent basis, not to mention be error-prone.</p><h2 id="So-now-what"><a href="#So-now-what" class="headerlink" title="So now what?"></a>So now what?</h2><p>When all this is put together, there are a LOT of individual tasks to be run. It’s relatively easy to queue everything all our projects and just let them all run, but if there are problems mid way through the process, it can be difficult to recover. This can be compounded by the fact that many of our products generally need to be deployed in a certain order, and while they do recover gracefully if they are done in the wrong order, it can result in some downtime until everything is complete.</p><p>One alternative that was discussed, which we did for a little while, was to do each project one at a time, and not starting the next until everything was deployed successfully. Since we aren’t <em>quite</em> ready for scheduling our deployments yet, this means one or more people need to stay up and baby sit the entire process, which can easily take a couple hours. If something did error out, then the time it took to identify and correct the issue would be added to the total time. This worked for a little while, but as we began to scale it was obvious this wouldn’t work long term.</p><h2 id="Chain-Deployments"><a href="#Chain-Deployments" class="headerlink" title="Chain Deployments"></a>Chain Deployments</h2><p>Enter the Octopus step template <code>Chain Deployment</code>. This is a community-provided PowerShell script that makes use of Octopus’ open API to allow one project to automatically trigger the deployment of another project. It is pretty configurable to allow for different applications, and it seemed like an obvious solution to our problem. </p><p>Using this, we could have configured each of our projects to trigger the release of the next project in line, but since we also want to be able to deploy a specific product independently from the rest, we instead opted to make one more project, which we call <code>_Deploy</code>.</p><p>This project is basically only responsible for the deployment of all of our products at the end of the release cycle. The version number for each release of <code>_Deploy</code> matches that of our flagship product, and it’s mostly just a series of Chain Deployment tasks. Each of the tasks are configured to wait until the chained deployment is complete before moving to the next, which effectively pauses the release process if an error occurs.</p><p>However, this was not as simple as creating a project with 7 Chain Deployment steps and calling it a day. As I mentioned earlier, all our products are released to a Beta program. In our case, we will release new code to our beta customers immediately after a release cycle before pushing it to our remaining customers after the following cycle. We can’t just use Chain Deployment, as it would either always push the most recent version to all environments (or attempt to, anyway - the lifecycle would prohibit it), or we would have to edit the project steps every release to have the specific version number of each of the products.</p><p>That first option is unacceptable, and the second would run into issues if we have to release a patch or hotfix to a given product - we would have to create an entirely new release with the new version numbers and promote it along the lifecycle, which can take a while. In an ideal world, we could release only the impacted projects to the impacted environments, and then update <code>_Deploy</code> to use new version going forward.</p><h2 id="Making-it-all-work"><a href="#Making-it-all-work" class="headerlink" title="Making it all work"></a>Making it all work</h2><p>So how do we make it work then? Instead of the 7 steps you might expect, we have 14 - each of our Chain Deployment steps also has an associated Deploy a Package step to accompany it.</p><p>Keep in mind that the <code>_Deploy</code> project <em>still</em> does not actually do any work - it only triggers the other projects to deploy. Instead, we scope the Deploy a Package steps to only work in a <code>Testing</code> environment (which coincidentally isn’t used in any of our lifecycles), and then configure the Chain Deployment to reference the package version that is used in that step. Here’s what it looks like:</p><p><img src="Project Steps.png" alt=""><br><img src="Deploy Step Details.png" alt=""></p><p>As you can see, we also group each Chain Deployment/Deploy a Package so we can skip the entire process and don’t accidentally the whole thing.</p><p>The other nice thing of doing this is that when we create the release we get the same package selection list that every other product has, and it can be changed just like any other project mid-stream. This allows us to keep the process exactly the same from release to release, only changing the packages it uses to do so, which means we not only avoid the issue of the latest version going to an environment before we want, but we also can change the releases mid-cycle (for things like patches) by just updating the packages used.</p><p><img src="Create Release.png" alt=""></p><p>A keen eye might notice that we only have 6 packages in the list. This is because our flagship product isn’t quite done with the conversion to Octopus yet, so there is no package to deploy. Instead, we use the version number of the <code>_Deploy</code> release to determine what version number to use for that project.</p><p>I also feel I should point out that this only works because all our projects are configured to have release numbers that match a specific package’s version, and that package is the one referenced by the <code>_Deploy</code> project. </p><h2 id="Now-what"><a href="#Now-what" class="headerlink" title="Now what?"></a>Now what?</h2><p>We’ve been using this project for a little while now, and we’ve found that setting this up not only made things easier, but more efficient. Since the output of the chained deployments (or at least, some of it) is displayed when looking at the <code>_Deploy</code> process, it’s easier to gauge how well things are progressing. Not having every possible task queued all at once also helps the overall process cope with changes or occasional one-off tasks that need to be done during a deployment. It’s also easier to on-board new people to how the deployment process works - create the release and click a button. </p><p>No matter how we look at it, this has been a net gain for our deployment process, and I hope it inspires you to think outside the box to do something simple yet powerful for yours.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;We use Octopus Deploy at my workplace to handle all of our releases. The tool is one of the best I’ve had the pleasure of dealing with, and the more I interact with it, the more I realize just how powerful, yet flexible, it is. I will gladly recommend it to anyone who is looking for a way of releasing any kind of software. &lt;/p&gt;
&lt;p&gt;However, there is always room for improvement. In this case, not necessarily improvement with the software package, but how we use it.
    
    </summary>
    
    
      <category term="Devops" scheme="http://kingofzeal.github.io/fuzzy-spork/tags/Devops/"/>
    
      <category term="Deployment" scheme="http://kingofzeal.github.io/fuzzy-spork/tags/Deployment/"/>
    
      <category term="Octopus Deploy" scheme="http://kingofzeal.github.io/fuzzy-spork/tags/Octopus-Deploy/"/>
    
  </entry>
  
  <entry>
    <title>Managing Expectations</title>
    <link href="http://kingofzeal.github.io/fuzzy-spork/2017/08/02/Managing-Expectations/"/>
    <id>http://kingofzeal.github.io/fuzzy-spork/2017/08/02/Managing-Expectations/</id>
    <published>2017-08-02T18:33:27.000Z</published>
    <updated>2018-02-01T14:28:15.682Z</updated>
    
    <content type="html"><![CDATA[<p>This morning I realized that, as programmers, we frequently make assumptions about the software we write which seem to be reasonable, but aren’t completely thought out.<a id="more"></a></p><p>I have an older (second generation) iPad that I mostly use for playing games and managing a media server I have set up in my house. Occasionally I will use it as a note-taking device, but honestly it can’t do much more, and I don’t need it to. Since it’s an older device, it’s no longer receiving the latest-and-greatest iOS, and seems to be going through a kind of planned obsolescence that many other people have also noticed in aging iOS devices.</p><p>I recently downloaded a new game for it, an idle-builder type game. As with most games of this type, it has a mechanism where you can continue to earn the game currency even when the app is closed. However, the (in this case, problematic) implementation gives some insight into the mind of the developer. I obviously don’t have access to the code, and I can only guess at what’s going on, but the theory I have points to the developer having reasonable but incorrect assumptions that lead to a way of processing that is efficient (and if slightly changed could even be pretty clever), but equally incorrect.</p><p>Much of this is exposed because my hardware is older, slower and generally less stable than most of the devices on the market. As such, things tend to crash. A lot. I’ve gotten used to it, and generally don’t tolerate apps that frequently crash before even getting to a point where I can interact with them. However, in this case it’s just stable enough that I can play for a decent amount of time before it gets to that point. What I noticed was that when recovering from a crash, I would get the offline compensation not for the time it took me to reopen the app, but since the last time <em>I gracefully closed it</em>. </p><p>I found that doing certain actions can trigger a crash fairly reliably (again, on my device - I don’t suspect this is possible on newer devices). As I played with it some more, I found that when I perform normal actions that increase how much I get while offline and trigger a crash, it comes back online and gives the reward based on the <em>current</em> (now updated) rate, not the original rate. Combine this with a continuously growing time frame and I was able to advance much quicker than was probably intended by the developer.</p><h2 id="So-what’s-going-on"><a href="#So-what’s-going-on" class="headerlink" title="So what’s going on?"></a>So what’s going on?</h2><p>First, I want to point out that I’m not an iOS developer, and have never touched iOS languages, so I may not be using the correct terminology. From what I can tell, the app is wired into an event that is fired whenever the app goes into standby. This event is raised if you go to the app switcher, when a notification box is displayed, etc - basically any time the app loses focus for any reason. When the event is raised, a local DateTime setting is set with the current clock value. Then, when the app is restored from the standby state, it takes <code>(DateTime.Now - [Saved DateTime]) * [current offline rate]</code> and gives you that amount of currency.</p><p>At the face of it, this seems a perfectly reasonable calculation. Since the DateTime is saved whenever the app goes into <em>any</em> standby state, including if you open the app switcher to manually kill the app, and the offline rate doesn’t change while you aren’t in the app, and it makes it difficult to “game” the system. This is still prone to adjustments of the system clock (ie, manually adjusting the clock forwards or backwards to make it seem as if more time has passed than it actually has), but those can be countered by other means and I didn’t check to see if they were handled or not.</p><p>However, it seems the saved DateTime value is <em>not</em> updated on a crash, or any other kind of event for that matter (like buying something, or literally any user interaction) - only when the app goes to standby. As a result, I’m able to exploit the instability of the app running on my device to force a crash, and then reload it, and take advantage of the fact that the app doesn’t know that it’s been opened before. Additionally, since all the other saved values of the game (like the offline earning rate) are saved as soon as possible, when the calculation is performed at start up, you not only get credit for the time but at the higher rate.</p><h2 id="Real-world-applications"><a href="#Real-world-applications" class="headerlink" title="Real world applications"></a>Real world applications</h2><p>I write this not from the perspective of how to take advantage of a programmer’s fallacy, but what we as programmers can learn from this. And for me, the lesson is to challenge all your assumptions. The biggest assumption this developer made was that the event that fires on standby will <em>always</em> fire, no matter what. There are other minor assumptions that were made, including that because a a device has a compatible OS version the app can be run on that device, but when combined, they allow someone to take advantage of the built-in mechanics to do things that weren’t necessarily intended.</p><p>In this case, it’s just a game - an argument can be made that nobody is really being harmed. However, the same lesson can be applied to other, perhaps more critical, areas as well like:</p><ul><li>“We don’t need HTTPS/SSL because it’s an internal resource”, or “it’s secured by a VPN”</li><li>“We don’t need to validate information on the server because the client can handle that and having it in two places isn’t DRY”</li><li>“The operating system didn’t change any relevant APIs, so we can support the older version to be more compatible”</li><li>“We have control over the API and the client code, so we can change anything to suit our needs”</li></ul><p>Some assumptions might be valid, and in some cases the cost to remedy a faulty assumption might be deemed too high for the risk it exposes. The goal is not to make sure everything is perfect, but to examine the often unspoken reasons for doing things a particular way, make sure it’s clear <em>why</em> it was done, and think of uncommon events that could lead to unexpected behavior.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;This morning I realized that, as programmers, we frequently make assumptions about the software we write which seem to be reasonable, but aren’t completely thought out.
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>The Non-standard Developer</title>
    <link href="http://kingofzeal.github.io/fuzzy-spork/2017/04/05/The-Non-standard-Developer/"/>
    <id>http://kingofzeal.github.io/fuzzy-spork/2017/04/05/The-Non-standard-Developer/</id>
    <published>2017-04-05T16:00:00.000Z</published>
    <updated>2018-02-01T14:28:15.682Z</updated>
    
    <content type="html"><![CDATA[<p>I recently read <a href="https://medium.freecodecamp.com/my-journey-to-becoming-a-web-developer-from-scratch-without-a-cs-degree-2-years-later-and-what-i-4a7fd2ff5503#.57ujsobff" target="_blank" rel="noopener">this really awesome atricle</a> written by a developer who had no formal education or background and his journey to becoming a front-end developer. Having gone through a somewhat similar transformation, I was inspired to also write about my own transition into programming without a traditional programming background. <a id="more"></a></p><h2 id="Who-are-you-anyway"><a href="#Who-are-you-anyway" class="headerlink" title="Who are you anyway?"></a>Who are you anyway?</h2><p>A fair question, and one I’m going to avoid almost entirely. Instead, I’m going to say that my formal education is in business, specifically accounting, and that my transition into pure development wasn’t radical, but a career evolution. When I graduated college, I was hired to an organization that had recently implemented a new ERP (enterprise resource planning - think Quickbooks on steroids) software package and wanted someone who knew both business concepts as well as technically/programming concepts. I had some minor self-tought programming experience by that point, which I had demonstrated during my school days and ultimately helped in securing the position.</p><p>I was able to get a handle on the application reasonably quick, but I didn’t know or understand much about this “object oriented programming” thing I was thrown into. Thankfully, this company also had a small programming deparment, and eventually I was brought into the fold of that team - working on a different application from anyone else, but still. I was quickly introduced to the concepts of agile, lean programming and application lifecycles, and during slow periods, when requests for changes for my application weren’t overwhelming, I was mentored in <em>real</em> programming. I was introduced to C#, taught best practices, and even assisted on some non-critical software projects the main programming department was involved with. I was exposed to more advanced patterns, both by reviewing the code written by my peers and by my own research. </p><p>As I learned more, I became more intrigued with the devops side of things. Sure, I enjoyed writing code; I had a few utilities I wrote for myself on my personal computer to help with some common tasks, and I was very proud that I was able to make a computer do what I wanted without (much) assistance from others. Within the ERP application I was in charge of I was even able to implement some advanced functionality that would not have been possible without the knowledge I had learned. But, with the support of those in charge, I was given an opportunity to explore the devops and application lifecycle side of things with the ultimate goal of being able to deploy changes made in a development environment to production in a way that was both SOX compliant and friendly to non-devlopers. I spent about a year putting it together, and ended up publishing a series of posts about it, which has been pretty well recieved by the community.</p><p>Ultimately, however, being in a constant ‘maintenance mode’ was draining, and new development opportunities were limited (by that time the programming department was all but eliminated), so I decided to leave and become a full-time C# developer.</p><h2 id="Imposter-Syndrome-is-real"><a href="#Imposter-Syndrome-is-real" class="headerlink" title="Imposter Syndrome is real"></a>Imposter Syndrome is real</h2><p>Back to the article. One thing the author doesn’t really talk about directly is Imposter Syndrome, which is something I experienced for a while after starting my new role. For those who don’t know, this is the feeling that you are somewhere you don’t belong, despite all evidence to the contrary. I think there are many people who have to deal with this - especially in programming carrers, where many people arrive in a programming role from non-traditional (non CS) backgrounds. There are many excellent resources around the subject which helped me, including books such as <a href="https://bigmachine.io/products/the-imposters-handbook/" target="_blank" rel="noopener">The Imposters Handbook</a>, and even posts by <a href="http://www.hanselman.com/blog/ImAPhonyAreYou.aspx" target="_blank" rel="noopener">people far more talented than me</a>. Still, it was difficult moving to a “real” developer role, and it wasn’t easy to shake the imposter feeling. However, as I become more comfortable with my new collegues (and the codebase for that matter), I was able to move past it and focus on being a better developer. Now I’m in a position where I can share my knowledge and experiences and hopefully offer a unique perspective to others so we can build the best product we can.</p><h2 id="What-I’ve-learned"><a href="#What-I’ve-learned" class="headerlink" title="What I’ve learned"></a>What I’ve learned</h2><ul><li>I think first and foremost, you don’t need a CS degree or formal education to become a programmer. I’m not saying that those programs are useless or that nobody should consider them, just that unlike other career choices (like accounting, for example) it’s not essential to take them to be a good developer. What matters more is the willingness to learn and share, being open to new ways of doing things, and having confidence in your abilities.</li><li>Always be learning. New languages come out every day, new patterns are being shared, and things are always evolving. This doesn’t necessarily mean you shouldn’t have a primary or preferred language in which you operate, but at least understand what other languages exist to complement your chosen one and how to use them. Modern languages are also changing; new features are being added and new ways of doing things being thought of, so pay attention to those as well.</li><li>Don’t be afraid to fight for what you think is right. When I first started my new role as a programmer, I was given a task to implement a new library into our product. However, after spending a day trying to tweak it and force it to work, I came to the conclusion that it wouldn’t work for us, and I said as much to the team. After some discussion we all agreed and ultimately we ended up writing our own library to handle the task, which both looks and operates much better than the original solution. It felt akward for me to challenge something so early in my new role (especially since it was my first pure programming role), but looking back I’m glad I did, as it ended up being a much better product because of it.</li></ul><h2 id="Long-Story-Longer"><a href="#Long-Story-Longer" class="headerlink" title="Long Story Longer"></a>Long Story Longer</h2><p>At the end of the day, the biggest takeaway I can offer is that the path to being a programmer is much wider than other careers, and don’t be afraid to persue it just because you don’t have the formal education in the field. Have the passion to learn and practice, and you’ll fit right in with the rest of us.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;I recently read &lt;a href=&quot;https://medium.freecodecamp.com/my-journey-to-becoming-a-web-developer-from-scratch-without-a-cs-degree-2-years-later-and-what-i-4a7fd2ff5503#.57ujsobff&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;this really awesome atricle&lt;/a&gt; written by a developer who had no formal education or background and his journey to becoming a front-end developer. Having gone through a somewhat similar transformation, I was inspired to also write about my own transition into programming without a traditional programming background.
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>On deployments and distribution</title>
    <link href="http://kingofzeal.github.io/fuzzy-spork/2016/10/11/On-deployments-and-distribution/"/>
    <id>http://kingofzeal.github.io/fuzzy-spork/2016/10/11/On-deployments-and-distribution/</id>
    <published>2016-10-11T12:00:00.000Z</published>
    <updated>2018-02-01T14:28:15.682Z</updated>
    
    <content type="html"><![CDATA[<p>Ever since I started programming, I’ve been fascinated with what you can do with a codebase - not just the act of programming, but building and deploying it as well. For a programming company, the less time programmers have to work on building or deploying their code, the more productive they can be. The automation of these things can have a huge benefit.<a id="more"></a></p><p>I’m sure many who may be reading this already have something in place to automatically build code, either on check-in, at a specific time, or both. Some may even have a system in place to automatically deploy code internally or to customers. But what is the real benefit from these things?</p><p>In many ways, having automated build and deployment solutions are as invaluable as have a version control solution. It doesn’t ultimately matter what you use to accomplish the task, but having something puts you in a much better place than not having anything. I, and I’m sure many others, have gotten so used to having such systems that I run my own to take care of things. Even this simple blog is version controlled and automatically deployed. At this point, it’s more habit than anything. My personal projects are all run through a build process on commit (I haven’t gotten to a deployment, for various reasons, but I’m working on it). If there is a perceived benefit from doing this on projects/programs that have little to no impact, how much more benefit is there for a company whose existance relies on getting code built and out the door?</p><h2 id="Automated-Build-Solution"><a href="#Automated-Build-Solution" class="headerlink" title="Automated Build Solution"></a>Automated Build Solution</h2><p>This is the easy one. If you can’t build your code, then you have nothing to ship. But why should you have an automated build solution? Simply put, reliability. There’s an interesting mentality that arises from using source control: Code that isn’t checked in doesn’t exist. Having a build environment separate from your development environment ensures that the only code that can be built is the code that is checked in. Sure, you can (and will) miss check-ins that cause a build to fail, but that’s the point. Even more dangerously, without a separate machine, it’s possible (and even inevitable) that you will build a feature that wasn’t meant to be released.</p><p>With a dedicated machine to build code, you can avoid all these issues. Additionally, with the right set of triggers and configuration, you won’t even need to give up your own time. Simply download the last build’s artifacts and you’re ready to deploy. This is even more helpful if your development cycle and deployment schedule don’t exactly line up - simply pull the last build from the last day of your development cycle. </p><p>Building on a dedicated machine also helps with stability. There are plenty of stories of projects that will, for one reason or another, build on one machine but not another. By eliminating the variance between machines (by using the <em>same</em> machine), you can accurately say 99% of the time that the problem is with the code, not the environment.</p><p>It’s also beneficial to have a build solution in place for a historical purpose: most solutions provide an easy way to track published artifacts over time. If a version of your code is released that has a bug, it’s easy to rollback to the last known working version, since you generally still have those artifacts. Without them, the only thing that can be done is to attempt to fix the bug, often while facing immense pressure from executives and customers. </p><h2 id="Automated-Deployment-Solution"><a href="#Automated-Deployment-Solution" class="headerlink" title="Automated Deployment Solution"></a>Automated Deployment Solution</h2><p>There’s nothing that says the build solution and the deployment solution can’t be the same thing. I’ve worked with a build environment that has a large number of deployment steps, and a single build step. There’s nothing wrong with such a system (and in some cases it can make sense), but know that it might not always be the best option.</p><p>Oddly enough, build solutions are generally found in most programming businesses but deployment solutions aren’t as common. Many times, the software being released doesn’t have a well-defined customer base, or a customer base that is so broad that such a system is deemed impractical. However, even in those situations a deployment solution could be a reasonable time saver.</p><p>If a product is being deployed solely for internal use, a deployment of a product takes an abnormally long time, or if there are many complicated steps to deploy a product, you will almost always benefit from an automated deployment system. Not only does it help to organize where things should be deployed to, but it can do everything that is needed accurately and reliably. This isn’t to say that there won’t be problems - deployments need testing, just like everything else. However, you can be assured that every deployment, given the same settings, will always do the same thing. Once it has been set up, you will generally not need to look at it again.</p><h2 id="Other-Thoughts"><a href="#Other-Thoughts" class="headerlink" title="Other Thoughts"></a>Other Thoughts</h2><p>Personally, I have always used <a href="https://www.jetbrains.com/teamcity/" target="_blank" rel="noopener">TeamCity</a> for my build system, even for personal projects. It has an easy-to-use interface, allows for running arbitrary scripts (helpful if you want to make it a deployment system), gets updates on a regular basis, and has a lot of plugins and features to support any type of project. The best part: it’s free for up to 20 configurations and 3 build agents (runners).</p><p>For a deployment solution, I’ve used TeamCity to handle that as well, and it does a reasonable job at it. It requires more configuration than probably should be expected, but it still performs as expected. However, for more complex deployments, I’ve grown fond of <a href="https://octopus.com/" target="_blank" rel="noopener">Octopus Deploy</a>. It isolates deployment processes from deployment targets in a way that makes it very easy to expand either. The focus is on the Microsoft stack (with nice native support for IIS and Windows Services), but can be used for almost anything. It is also available for free (for up to 20 of any combination of projects, target machines and users), but the time it takes to set it up and configure it doesn’t lend itself well to personal projects, as they are generally only deployed to a single location. </p><p>Finally, don’t discount other systems, such as <a href="https://travis-ci.org/" target="_blank" rel="noopener">Travis CI</a>, which excel at projects that are intrepreted, like Javascript and PHP (like this blog, which is generated with a Node package <code>Hexo</code>). Since these aren’t compiled in the traditional sense, such systems can be used to run unit tests and deploy on success. Travis in particular has great integration with Github, where you can see Pass/Fail statuses and even enforce checks on pull requests.</p><p>I’m sure many who are reading this are already using most, if not all, these things, but for those who still are not: Take the time now and look into setting something up. You’ll thank yourself for it tomorrow.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Ever since I started programming, I’ve been fascinated with what you can do with a codebase - not just the act of programming, but building and deploying it as well. For a programming company, the less time programmers have to work on building or deploying their code, the more productive they can be. The automation of these things can have a huge benefit.
    
    </summary>
    
    
      <category term="Devops" scheme="http://kingofzeal.github.io/fuzzy-spork/tags/Devops/"/>
    
      <category term="Build" scheme="http://kingofzeal.github.io/fuzzy-spork/tags/Build/"/>
    
      <category term="Deployment" scheme="http://kingofzeal.github.io/fuzzy-spork/tags/Deployment/"/>
    
  </entry>
  
  <entry>
    <title>The Fuzzy Spork</title>
    <link href="http://kingofzeal.github.io/fuzzy-spork/2016/10/05/The-Fuzzy-Spork/"/>
    <id>http://kingofzeal.github.io/fuzzy-spork/2016/10/05/The-Fuzzy-Spork/</id>
    <published>2016-10-05T12:00:00.000Z</published>
    <updated>2018-02-01T14:28:15.682Z</updated>
    
    <content type="html"><![CDATA[<p>A fascinating picture, isn’t it? A fuzzy spork. It conjures images that raise far more questions than they answer. What does it mean? What could make a spork fuzzy? Is it safe? Is it supposed to be like that? Is it really a fuzzy spork or is it a sporked fuzzy? Where are the adults?<a id="more"></a></p><p>Honestly, I can’t give any answers to any of these, especially that last one. However, I can honestly say that if I ever do see a fuzzy spork in real life, I’m going to be looking very closely to see just what’s up with it.</p><p>And that’s what this is all about: taking a closer look at things that are strange and mystifying, trying to understand it, and then sharing what we now know with everyone else.</p><p>I’m sure it won’t always be the most illuminating journey, but one thing is for sure: someone, somewhere, is going to have fun taking it. And it’s probably going to be me.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;A fascinating picture, isn’t it? A fuzzy spork. It conjures images that raise far more questions than they answer. What does it mean? What could make a spork fuzzy? Is it safe? Is it supposed to be like that? Is it really a fuzzy spork or is it a sporked fuzzy? Where are the adults?
    
    </summary>
    
    
  </entry>
  
</feed>
